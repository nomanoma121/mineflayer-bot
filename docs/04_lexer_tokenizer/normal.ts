/**
 * ğŸŸ¡ 04_lexer_tokenizer ä¸­ç´šå•é¡Œ: é«˜åº¦ãªå­—å¥è§£ææ©Ÿèƒ½å®Ÿè£…
 * 
 * ã‚ˆã‚Šè¤‡é›‘ãªãƒˆãƒ¼ã‚¯ãƒ³å‡¦ç†ã¨å­—å¥è§£ææ©Ÿèƒ½ã‚’å®Ÿè£…ã—ã¦ãã ã•ã„ã€‚
 * ã“ã®å•é¡Œã§ã¯ã€æ­£è¦è¡¨ç¾ãƒ‘ã‚¿ãƒ¼ãƒ³ã€ã‚¨ãƒ©ãƒ¼å›å¾©ã€ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å‡¦ç†ã‚’å­¦ã³ã¾ã™ã€‚
 */

// ===== é«˜åº¦ãªãƒˆãƒ¼ã‚¯ãƒ³ã‚¿ã‚¤ãƒ— =====

export enum AdvancedTokenType {
  // åŸºæœ¬ãƒˆãƒ¼ã‚¯ãƒ³
  KEYWORD = 'KEYWORD',
  IDENTIFIER = 'IDENTIFIER',
  NUMBER = 'NUMBER',
  STRING = 'STRING',
  BOOLEAN = 'BOOLEAN',
  
  // æ¼”ç®—å­ã¨ãƒ‡ãƒªãƒŸã‚¿
  OPERATOR = 'OPERATOR',
  COMPARISON = 'COMPARISON',
  LOGICAL = 'LOGICAL',
  ASSIGNMENT = 'ASSIGNMENT',
  DELIMITER = 'DELIMITER',
  
  // ç‰¹æ®Šãƒˆãƒ¼ã‚¯ãƒ³
  COMMENT = 'COMMENT',
  WHITESPACE = 'WHITESPACE',
  NEWLINE = 'NEWLINE',
  VARIABLE = 'VARIABLE',
  
  // åˆ¶å¾¡æ§‹é€ 
  BLOCK_START = 'BLOCK_START',
  BLOCK_END = 'BLOCK_END',
  
  // ã‚¨ãƒ©ãƒ¼å‡¦ç†
  INVALID = 'INVALID',
  EOF = 'EOF'
}

// ===== é«˜åº¦ãªãƒˆãƒ¼ã‚¯ãƒ³å®Ÿè£… =====

export class AdvancedToken {
  constructor(
    public type: AdvancedTokenType,
    public value: string,
    public line: number,
    public column: number,
    public position: number,
    public length: number
  ) {}

  /**
   * ãƒˆãƒ¼ã‚¯ãƒ³ã®è©³ç´°æƒ…å ±ã‚’å–å¾—ã—ã¾ã™
   */
  getInfo(): TokenInfo {
    // TODO: ãƒˆãƒ¼ã‚¯ãƒ³æƒ…å ±ã®è©³ç´°åŒ–
    // ãƒ’ãƒ³ãƒˆ1: ä½ç½®æƒ…å ±ã®è©³ç´°åŒ–
    // ãƒ’ãƒ³ãƒˆ2: ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã®è¿½åŠ 
    // ãƒ’ãƒ³ãƒˆ3: ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆæƒ…å ±
    
    return new TokenInfo(
      this.type,
      this.value,
      new Position(this.line, this.column),
      new Location(this.position, this.length),
      this.extractMetadata()
    );
  }

  /**
   * ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡ºã—ã¾ã™
   */
  private extractMetadata(): Map<string, any> {
    const metadata = new Map<string, any>();
    
    switch (this.type) {
      case AdvancedTokenType.NUMBER:
        metadata.set('isInteger', Number.isInteger(Number(this.value)));
        metadata.set('numericValue', Number(this.value));
        break;
      case AdvancedTokenType.STRING:
        metadata.set('length', this.value.length - 2); // å¼•ç”¨ç¬¦ã‚’é™¤ã
        metadata.set('isMultiline', this.value.includes('\n'));
        break;
      case AdvancedTokenType.IDENTIFIER:
        metadata.set('isKeyword', this.isKeyword());
        metadata.set('isReserved', this.isReserved());
        break;
    }
    
    return metadata;
  }

  /**
   * ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‹ãƒã‚§ãƒƒã‚¯ã—ã¾ã™
   */
  private isKeyword(): boolean {
    const keywords = ['IF', 'ELSE', 'WHILE', 'FOR', 'FUNCTION', 'RETURN', 'TRY', 'CATCH'];
    return keywords.includes(this.value.toUpperCase());
  }

  /**
   * äºˆç´„èªã‹ãƒã‚§ãƒƒã‚¯ã—ã¾ã™
   */
  private isReserved(): boolean {
    const reserved = ['NULL', 'UNDEFINED', 'TRUE', 'FALSE'];
    return reserved.includes(this.value.toUpperCase());
  }

  /**
   * ãƒˆãƒ¼ã‚¯ãƒ³ã‚’æ–‡å­—åˆ—ã¨ã—ã¦è¡¨ç¾ã—ã¾ã™
   */
  toString(): string {
    return `${this.type}(${this.value}) at ${this.line}:${this.column}`;
  }
}

// ===== ä½ç½®æƒ…å ±ç®¡ç† =====

export class Position {
  constructor(
    public line: number,
    public column: number
  ) {}

  toString(): string {
    return `${this.line}:${this.column}`;
  }

  equals(other: Position): boolean {
    return this.line === other.line && this.column === other.column;
  }
}

export class Location {
  constructor(
    public start: number,
    public length: number
  ) {}

  get end(): number {
    return this.start + this.length;
  }

  contains(position: number): boolean {
    return position >= this.start && position < this.end;
  }
}

export class TokenInfo {
  constructor(
    public type: AdvancedTokenType,
    public value: string,
    public position: Position,
    public location: Location,
    public metadata: Map<string, any>
  ) {}
}

// ===== æ­£è¦è¡¨ç¾ãƒ™ãƒ¼ã‚¹ã®å­—å¥è§£æå™¨ =====

export class RegexLexer {
  private patterns: Map<AdvancedTokenType, RegExp> = new Map();
  private input: string = '';
  private position: number = 0;
  private line: number = 1;
  private column: number = 1;
  private tokens: AdvancedToken[] = [];

  constructor() {
    this.setupPatterns();
  }

  /**
   * ãƒˆãƒ¼ã‚¯ãƒ³ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’è¨­å®šã—ã¾ã™
   */
  private setupPatterns(): void {
    // TODO: æ­£è¦è¡¨ç¾ãƒ‘ã‚¿ãƒ¼ãƒ³ã®å®šç¾©
    // ãƒ’ãƒ³ãƒˆ1: ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒ‘ã‚¿ãƒ¼ãƒ³
    // ãƒ’ãƒ³ãƒˆ2: è­˜åˆ¥å­ãƒ‘ã‚¿ãƒ¼ãƒ³
    // ãƒ’ãƒ³ãƒˆ3: ãƒªãƒ†ãƒ©ãƒ«ãƒ‘ã‚¿ãƒ¼ãƒ³
    // ãƒ’ãƒ³ãƒˆ4: æ¼”ç®—å­ãƒ‘ã‚¿ãƒ¼ãƒ³
    
    // æ•°å€¤ãƒ‘ã‚¿ãƒ¼ãƒ³ï¼ˆæ•´æ•°ã€å°æ•°ã€ç§‘å­¦è¨˜æ³•ï¼‰
    this.patterns.set(AdvancedTokenType.NUMBER, /^-?\d+(\.\d+)?([eE][+-]?\d+)?/);
    
    // æ–‡å­—åˆ—ãƒ‘ã‚¿ãƒ¼ãƒ³ï¼ˆã‚·ãƒ³ã‚°ãƒ«ãƒ»ãƒ€ãƒ–ãƒ«ã‚¯ã‚©ãƒ¼ãƒˆã€ã‚¨ã‚¹ã‚±ãƒ¼ãƒ—å¯¾å¿œï¼‰
    this.patterns.set(AdvancedTokenType.STRING, /^"(?:[^"\\]|\\.)*"|^'(?:[^'\\]|\\.)*'/);
    
    // ãƒ–ãƒ¼ãƒ«å€¤
    this.patterns.set(AdvancedTokenType.BOOLEAN, /^(true|false)\b/i);
    
    // å¤‰æ•°ï¼ˆ$ã§å§‹ã¾ã‚‹ï¼‰
    this.patterns.set(AdvancedTokenType.VARIABLE, /^\$[a-zA-Z_][a-zA-Z0-9_]*/);
    
    // è­˜åˆ¥å­ï¼ˆã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’é™¤ãï¼‰
    this.patterns.set(AdvancedTokenType.IDENTIFIER, /^[a-zA-Z_][a-zA-Z0-9_]*/);
    
    // æ¯”è¼ƒæ¼”ç®—å­
    this.patterns.set(AdvancedTokenType.COMPARISON, /^(==|!=|<=|>=|<|>)/);
    
    // è«–ç†æ¼”ç®—å­
    this.patterns.set(AdvancedTokenType.LOGICAL, /^(&&|\|\||!)/);
    
    // ä»£å…¥æ¼”ç®—å­
    this.patterns.set(AdvancedTokenType.ASSIGNMENT, /^(=|\+=|-=|\*=|\/=)/);
    
    // ç®—è¡“æ¼”ç®—å­
    this.patterns.set(AdvancedTokenType.OPERATOR, /^[+\-*/()]/);
    
    // ãƒ‡ãƒªãƒŸã‚¿
    this.patterns.set(AdvancedTokenType.DELIMITER, /^[,;:.]/);
    
    // ã‚³ãƒ¡ãƒ³ãƒˆ
    this.patterns.set(AdvancedTokenType.COMMENT, /^\/\/.*$/m);
    
    // æ”¹è¡Œ
    this.patterns.set(AdvancedTokenType.NEWLINE, /^\n/);
    
    // ç©ºç™½
    this.patterns.set(AdvancedTokenType.WHITESPACE, /^[ \t]+/);
  }

  /**
   * å…¥åŠ›ã‚’å­—å¥è§£æã—ã¾ã™
   */
  tokenize(input: string): LexicalAnalysisResult {
    // TODO: æ­£è¦è¡¨ç¾ãƒ™ãƒ¼ã‚¹ã®å­—å¥è§£æ
    // ãƒ’ãƒ³ãƒˆ1: ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒãƒƒãƒãƒ³ã‚°ã®é †åº
    // ãƒ’ãƒ³ãƒˆ2: æœ€é•·ãƒãƒƒãƒã®é¸æŠ
    // ãƒ’ãƒ³ãƒˆ3: ã‚¨ãƒ©ãƒ¼å‡¦ç†
    // ãƒ’ãƒ³ãƒˆ4: ä½ç½®æƒ…å ±ã®æ›´æ–°
    
    this.input = input;
    this.position = 0;
    this.line = 1;
    this.column = 1;
    this.tokens = [];
    
    while (this.position < this.input.length) {
      const matched = this.matchToken();
      
      if (!matched) {
        // ãƒãƒƒãƒã—ãªã„æ–‡å­—ã¯ç„¡åŠ¹ãƒˆãƒ¼ã‚¯ãƒ³ã¨ã—ã¦å‡¦ç†
        this.addInvalidToken();
      }
    }
    
    // EOFãƒˆãƒ¼ã‚¯ãƒ³ã‚’è¿½åŠ 
    this.tokens.push(new AdvancedToken(
      AdvancedTokenType.EOF,
      '',
      this.line,
      this.column,
      this.position,
      0
    ));
    
    return new LexicalAnalysisResult(this.tokens, this.getErrors());
  }

  /**
   * ãƒˆãƒ¼ã‚¯ãƒ³ã‚’ãƒãƒƒãƒã—ã¾ã™
   */
  private matchToken(): boolean {
    const remainingInput = this.input.slice(this.position);
    
    // ãƒ‘ã‚¿ãƒ¼ãƒ³ã®å„ªå…ˆé †ä½é †ã«ãƒãƒƒãƒã‚’è©¦è¡Œ
    const orderedTypes = [
      AdvancedTokenType.COMMENT,
      AdvancedTokenType.STRING,
      AdvancedTokenType.NUMBER,
      AdvancedTokenType.BOOLEAN,
      AdvancedTokenType.VARIABLE,
      AdvancedTokenType.COMPARISON,
      AdvancedTokenType.LOGICAL,
      AdvancedTokenType.ASSIGNMENT,
      AdvancedTokenType.OPERATOR,
      AdvancedTokenType.DELIMITER,
      AdvancedTokenType.IDENTIFIER,
      AdvancedTokenType.NEWLINE,
      AdvancedTokenType.WHITESPACE
    ];
    
    for (const type of orderedTypes) {
      const pattern = this.patterns.get(type);
      if (pattern) {
        const match = remainingInput.match(pattern);
        if (match) {
          const value = match[0];
          
          // ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒã‚§ãƒƒã‚¯
          const tokenType = this.isKeyword(value, type) ? AdvancedTokenType.KEYWORD : type;
          
          this.addToken(tokenType, value);
          return true;
        }
      }
    }
    
    return false;
  }

  /**
   * ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‹ãƒã‚§ãƒƒã‚¯ã—ã¾ã™
   */
  private isKeyword(value: string, currentType: AdvancedTokenType): boolean {
    if (currentType !== AdvancedTokenType.IDENTIFIER) {
      return false;
    }
    
    const keywords = [
      'IF', 'ELSE', 'ENDIF', 'WHILE', 'ENDWHILE', 'FOR', 'ENDFOR',
      'FUNCTION', 'ENDFUNCTION', 'RETURN', 'TRY', 'CATCH', 'ENDTRY',
      'REPEAT', 'ENDREPEAT', 'SWITCH', 'CASE', 'DEFAULT', 'ENDSWITCH',
      'DEF', 'SAY', 'MOVE', 'GOTO', 'ATTACK', 'DIG', 'PLACE', 'WAIT'
    ];
    
    return keywords.includes(value.toUpperCase());
  }

  /**
   * ãƒˆãƒ¼ã‚¯ãƒ³ã‚’è¿½åŠ ã—ã¾ã™
   */
  private addToken(type: AdvancedTokenType, value: string): void {
    const token = new AdvancedToken(
      type,
      value,
      this.line,
      this.column,
      this.position,
      value.length
    );
    
    // ç©ºç™½ã¨ã‚³ãƒ¡ãƒ³ãƒˆä»¥å¤–ã®ãƒˆãƒ¼ã‚¯ãƒ³ã‚’ä¿å­˜
    if (type !== AdvancedTokenType.WHITESPACE && type !== AdvancedTokenType.COMMENT) {
      this.tokens.push(token);
    }
    
    this.updatePosition(value);
  }

  /**
   * ç„¡åŠ¹ãªãƒˆãƒ¼ã‚¯ãƒ³ã‚’è¿½åŠ ã—ã¾ã™
   */
  private addInvalidToken(): void {
    const char = this.input[this.position];
    this.addToken(AdvancedTokenType.INVALID, char);
  }

  /**
   * ä½ç½®æƒ…å ±ã‚’æ›´æ–°ã—ã¾ã™
   */
  private updatePosition(value: string): void {
    for (const char of value) {
      if (char === '\n') {
        this.line++;
        this.column = 1;
      } else {
        this.column++;
      }
      this.position++;
    }
  }

  /**
   * ã‚¨ãƒ©ãƒ¼æƒ…å ±ã‚’å–å¾—ã—ã¾ã™
   */
  private getErrors(): LexicalError[] {
    const errors: LexicalError[] = [];
    
    for (const token of this.tokens) {
      if (token.type === AdvancedTokenType.INVALID) {
        errors.push(new LexicalError(
          `Invalid character: '${token.value}'`,
          token.line,
          token.column
        ));
      }
    }
    
    return errors;
  }
}

// ===== ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å­—å¥è§£æå™¨ =====

export class StreamingLexer {
  private buffer: string = '';
  private lexer: RegexLexer = new RegexLexer();
  private pendingTokens: AdvancedToken[] = [];

  /**
   * ãƒ‡ãƒ¼ã‚¿ãƒãƒ£ãƒ³ã‚¯ã‚’è¿½åŠ ã—ã¾ã™
   */
  addChunk(chunk: string): AdvancedToken[] {
    // TODO: ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å‡¦ç†ã®å®Ÿè£…
    // ãƒ’ãƒ³ãƒˆ1: ãƒãƒƒãƒ•ã‚¡ç®¡ç†
    // ãƒ’ãƒ³ãƒˆ2: éƒ¨åˆ†ãƒˆãƒ¼ã‚¯ãƒ³ã®å‡¦ç†
    // ãƒ’ãƒ³ãƒˆ3: ãƒãƒ£ãƒ³ã‚¯å¢ƒç•Œã®å‡¦ç†
    
    this.buffer += chunk;
    
    // å®Œå…¨ãªè¡ŒãŒã‚ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
    const lines = this.buffer.split('\n');
    const tokens: AdvancedToken[] = [];
    
    // æœ€å¾Œã®è¡Œä»¥å¤–ã‚’å‡¦ç†
    for (let i = 0; i < lines.length - 1; i++) {
      const result = this.lexer.tokenize(lines[i] + '\n');
      tokens.push(...result.tokens);
    }
    
    // æ®‹ã‚Šã®éƒ¨åˆ†ã‚’ãƒãƒƒãƒ•ã‚¡ã«ä¿æŒ
    this.buffer = lines[lines.length - 1];
    
    return tokens;
  }

  /**
   * ãƒãƒƒãƒ•ã‚¡ã‚’å®Œäº†ã—ã¾ã™
   */
  flush(): AdvancedToken[] {
    if (this.buffer.length > 0) {
      const result = this.lexer.tokenize(this.buffer);
      this.buffer = '';
      return result.tokens;
    }
    return [];
  }
}

// ===== ã‚¨ãƒ©ãƒ¼å›å¾©æ©Ÿèƒ½ =====

export class ErrorRecoveryLexer extends RegexLexer {
  private errors: LexicalError[] = [];
  private recoveryStrategies: Map<string, RecoveryStrategy> = new Map();

  constructor() {
    super();
    this.setupRecoveryStrategies();
  }

  /**
   * ã‚¨ãƒ©ãƒ¼å›å¾©æˆ¦ç•¥ã‚’è¨­å®šã—ã¾ã™
   */
  private setupRecoveryStrategies(): void {
    // TODO: ã‚¨ãƒ©ãƒ¼å›å¾©æˆ¦ç•¥ã®è¨­å®š
    // ãƒ’ãƒ³ãƒˆ1: æ–‡å­—ã‚¹ã‚­ãƒƒãƒ—æˆ¦ç•¥
    // ãƒ’ãƒ³ãƒˆ2: åŒºåˆ‡ã‚Šæ–‡å­—æ¤œç´¢æˆ¦ç•¥
    // ãƒ’ãƒ³ãƒˆ3: ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ¤œç´¢æˆ¦ç•¥
    
    this.recoveryStrategies.set('skip_char', new SkipCharStrategy());
    this.recoveryStrategies.set('find_delimiter', new FindDelimiterStrategy());
    this.recoveryStrategies.set('find_keyword', new FindKeywordStrategy());
  }

  /**
   * ã‚¨ãƒ©ãƒ¼å›å¾©ã‚’å®Ÿè¡Œã—ã¾ã™
   */
  recoverFromError(position: number): number {
    // TODO: ã‚¨ãƒ©ãƒ¼å›å¾©ã®å®Ÿè£…
    // ãƒ’ãƒ³ãƒˆ1: æˆ¦ç•¥ã®é¸æŠ
    // ãƒ’ãƒ³ãƒˆ2: å›å¾©ã®å®Ÿè¡Œ
    // ãƒ’ãƒ³ãƒˆ3: ã‚¨ãƒ©ãƒ¼å ±å‘Š
    
    const strategies = ['find_delimiter', 'find_keyword', 'skip_char'];
    
    for (const strategyName of strategies) {
      const strategy = this.recoveryStrategies.get(strategyName);
      if (strategy) {
        const newPosition = strategy.recover(this.input, position);
        if (newPosition > position) {
          this.reportError(position, newPosition, strategyName);
          return newPosition;
        }
      }
    }
    
    // å›å¾©ã§ããªã„å ´åˆã¯1æ–‡å­—ã‚¹ã‚­ãƒƒãƒ—
    this.reportError(position, position + 1, 'skip_char');
    return position + 1;
  }

  /**
   * ã‚¨ãƒ©ãƒ¼ã‚’å ±å‘Šã—ã¾ã™
   */
  private reportError(start: number, end: number, strategy: string): void {
    const error = new LexicalError(
      `Syntax error recovered using ${strategy}`,
      this.line,
      this.column
    );
    this.errors.push(error);
  }

  /**
   * ã‚¨ãƒ©ãƒ¼æƒ…å ±ã‚’å–å¾—ã—ã¾ã™
   */
  getRecoveryErrors(): LexicalError[] {
    return [...this.errors];
  }
}

// ===== ã‚¨ãƒ©ãƒ¼å›å¾©æˆ¦ç•¥ =====

export interface RecoveryStrategy {
  recover(input: string, position: number): number;
}

export class SkipCharStrategy implements RecoveryStrategy {
  recover(input: string, position: number): number {
    return position + 1;
  }
}

export class FindDelimiterStrategy implements RecoveryStrategy {
  recover(input: string, position: number): number {
    const delimiters = [' ', '\n', '\t', ';', ',', '(', ')', '{', '}'];
    
    for (let i = position + 1; i < input.length; i++) {
      if (delimiters.includes(input[i])) {
        return i;
      }
    }
    
    return position;
  }
}

export class FindKeywordStrategy implements RecoveryStrategy {
  recover(input: string, position: number): number {
    const keywords = ['IF', 'WHILE', 'FOR', 'FUNCTION', 'DEF'];
    const remaining = input.slice(position);
    
    for (const keyword of keywords) {
      const index = remaining.toUpperCase().indexOf(keyword);
      if (index >= 0) {
        return position + index;
      }
    }
    
    return position;
  }
}

// ===== ã‚¨ãƒ©ãƒ¼ç®¡ç† =====

export class LexicalError {
  constructor(
    public message: string,
    public line: number,
    public column: number,
    public recoverable: boolean = true
  ) {}

  toString(): string {
    return `Lexical Error at ${this.line}:${this.column}: ${this.message}`;
  }
}

export class LexicalAnalysisResult {
  constructor(
    public tokens: AdvancedToken[],
    public errors: LexicalError[]
  ) {}

  /**
   * å­—å¥è§£æãŒæˆåŠŸã—ãŸã‹ãƒã‚§ãƒƒã‚¯ã—ã¾ã™
   */
  isSuccess(): boolean {
    return this.errors.length === 0;
  }

  /**
   * ç‰¹å®šã®å‹ã®ãƒˆãƒ¼ã‚¯ãƒ³ã‚’å–å¾—ã—ã¾ã™
   */
  getTokensByType(type: AdvancedTokenType): AdvancedToken[] {
    return this.tokens.filter(token => token.type === type);
  }

  /**
   * ãƒˆãƒ¼ã‚¯ãƒ³çµ±è¨ˆã‚’å–å¾—ã—ã¾ã™
   */
  getStatistics(): TokenStatistics {
    const typeCount = new Map<AdvancedTokenType, number>();
    
    for (const token of this.tokens) {
      const count = typeCount.get(token.type) || 0;
      typeCount.set(token.type, count + 1);
    }
    
    return new TokenStatistics(
      this.tokens.length,
      typeCount,
      this.errors.length
    );
  }
}

export class TokenStatistics {
  constructor(
    public totalTokens: number,
    public typeCount: Map<AdvancedTokenType, number>,
    public errorCount: number
  ) {}

  /**
   * æœ€ã‚‚å¤šã„ãƒˆãƒ¼ã‚¯ãƒ³å‹ã‚’å–å¾—ã—ã¾ã™
   */
  getMostCommonType(): AdvancedTokenType | null {
    let maxCount = 0;
    let mostCommon: AdvancedTokenType | null = null;
    
    for (const [type, count] of this.typeCount) {
      if (count > maxCount) {
        maxCount = count;
        mostCommon = type;
      }
    }
    
    return mostCommon;
  }
}

// ===== ãƒ‡ãƒ¢ã‚¯ãƒ©ã‚¹ =====

export class AdvancedLexerDemo {
  /**
   * é«˜åº¦ãªå­—å¥è§£ææ©Ÿèƒ½ã®ãƒ‡ãƒ¢ã‚’å®Ÿè¡Œã—ã¾ã™
   */
  public static runDemo(): void {
    console.log('=== Advanced Lexer Demo ===');

    // è¤‡é›‘ãªBotScriptã‚³ãƒ¼ãƒ‰
    const complexCode = `
      // è¤‡é›‘ãªé–¢æ•°å®šç¾©
      FUNCTION calculateDamage(baseDamage, multiplier, critChance)
        DEF result = baseDamage * multiplier
        IF $random <= critChance
          DEF result = result * 1.5
        ENDIF
        RETURN result
      ENDFUNCTION
      
      // å¤‰æ•°å®£è¨€ã¨è¨ˆç®—
      DEF playerHealth = 100.5
      DEF enemyAttack = 25.75
      DEF $criticalHit = 0.15
      
      // æ¡ä»¶åˆ†å²
      WHILE playerHealth > 0 && enemyAttack > 0
        DEF damage = calculateDamage(enemyAttack, 1.2, $criticalHit)
        DEF playerHealth = playerHealth - damage
        SAY "Player health: " + playerHealth
      ENDWHILE
    `;

    // æ­£è¦è¡¨ç¾å­—å¥è§£æå™¨ã®ãƒ†ã‚¹ãƒˆ
    console.log('\n--- Regex Lexer Test ---');
    const regexLexer = new RegexLexer();
    const result = regexLexer.tokenize(complexCode);
    
    console.log(`Tokens found: ${result.tokens.length}`);
    console.log(`Errors found: ${result.errors.length}`);
    
    // ãƒˆãƒ¼ã‚¯ãƒ³çµ±è¨ˆã®è¡¨ç¤º
    const stats = result.getStatistics();
    console.log(`Total tokens: ${stats.totalTokens}`);
    console.log(`Most common type: ${stats.getMostCommonType()}`);
    
    // ã‚¨ãƒ©ãƒ¼å›å¾©å­—å¥è§£æå™¨ã®ãƒ†ã‚¹ãƒˆ
    console.log('\n--- Error Recovery Lexer Test ---');
    const errorCode = `
      DEF invalid@name = 123
      SAY "Missing quote
      FUNCTION unclosed(param
      IF condition THEN // ç„¡åŠ¹ãªæ§‹æ–‡
    `;
    
    const errorLexer = new ErrorRecoveryLexer();
    const errorResult = errorLexer.tokenize(errorCode);
    
    console.log(`Recovery errors: ${errorLexer.getRecoveryErrors().length}`);
    for (const error of errorLexer.getRecoveryErrors()) {
      console.log(`  ${error.toString()}`);
    }
    
    // ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å­—å¥è§£æå™¨ã®ãƒ†ã‚¹ãƒˆ
    console.log('\n--- Streaming Lexer Test ---');
    const streamingLexer = new StreamingLexer();
    
    const chunks = [
      'DEF health = ',
      '100\nSAY "Player',
      ' spawned"\n',
      'MOVE forward'
    ];
    
    let totalStreamTokens = 0;
    for (const chunk of chunks) {
      const tokens = streamingLexer.addChunk(chunk);
      totalStreamTokens += tokens.length;
      console.log(`Chunk processed: ${tokens.length} tokens`);
    }
    
    const finalTokens = streamingLexer.flush();
    totalStreamTokens += finalTokens.length;
    console.log(`Final flush: ${finalTokens.length} tokens`);
    console.log(`Total streaming tokens: ${totalStreamTokens}`);

    console.log('\nAdvanced lexer demo completed');
  }
}